# Embeddings

Embeddings are numerical representations of text that capture **semantic meaning**.

Instead of matching keywords, embeddings allow systems to find text that *means the same thing* â€” even if the words differ.

---

## Why Embeddings Matter

Embeddings enable:
- Semantic search
- Similarity comparison
- Clustering and ranking
- Retrieval in RAG pipelines

---

## Example

These two sentences are semantically similar:

- â€œHow do I reset my password?â€
- â€œI forgot my login credentialsâ€

Embeddings place them **close together in vector space**, even though the words differ.

---

## In This Course

You will:
- Generate embeddings using OpenAI models
- Store them in a vector database
- Retrieve them efficiently at query time

---

ğŸ‘‰ **Next:** [Vector Databases](vector-databases.md)
